{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b114f8a8",
   "metadata": {},
   "source": [
    "# Example of using Pinecode as embeddings DB for Neural Search of Youtube videos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38ab633",
   "metadata": {},
   "source": [
    "## Load libraries and setup 3rd party applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cd4e9a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-22 10:36:59.638155: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-22 10:37:00.244643: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-22 10:37:00.244740: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-22 10:37:00.244748: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from googleapiclient.discovery import build # pip install --upgrade google-api-python-client\n",
    "from pathlib import Path\n",
    "import json\n",
    "import requests\n",
    "import urllib\n",
    "from os.path import exists\n",
    "import os\n",
    "\n",
    "# !sudo apt update -y && sudo apt install ffmpeg -y\n",
    "#!pip install --upgrade protobuf\n",
    "#!pip install --upgrade tensorflow\n",
    "#!pip uninstall keras\n",
    "#!pip install --upgrade keras\n",
    "from pytube import YouTube  # !pip install pytube\n",
    "from pytube.exceptions import RegexMatchError\n",
    "import scrapetube\n",
    "import youtube_dl\n",
    "\n",
    "from tqdm.auto import tqdm  # !pip install tqdm\n",
    "\n",
    "import whisper # !pip install git+https://github.com/openai/whisper.git\n",
    "import torch  # pytorch install steps: pytorch.org\n",
    "\n",
    "import pinecone # pip install --upgrade pinecone-client\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8a13bd",
   "metadata": {},
   "source": [
    "## Define Inputs\n",
    "channel_names is a list of youtube channel names to index<br>\n",
    "pinecone_api_key and google_api_key requires free registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d34de34",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_dir = './audio'\n",
    "channel_names = ['paulharveyarchives']\n",
    "pinecone_api_key = 'c65fa925-08e1-4af0-b08b-1104c6ffba25' # https://app.pinecone.io/projects\n",
    "google_api_key = 'AIzaSyAIIY6OsTws8dTfoyxNmJLmnfmH2f859Fw' # https://console.cloud.google.com/apis/dashboard\n",
    "\n",
    "youtube_dl_options = {\n",
    "    'skip_download': True,\n",
    "    'ignoreerrors': True\n",
    "}\n",
    "\n",
    "# name of Pinecone index to use\n",
    "index_id = \"audio\"\n",
    "# we encode and insert in batches of 64\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6437cb1",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfe1e14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_video_in_channel(channel_id):\n",
    "    video_IDs = []\n",
    "    video_titles = {}\n",
    "    videos = scrapetube.get_channel(channel_id)\n",
    "\n",
    "    try:\n",
    "        for video in videos:\n",
    "            video_IDs.append(video['videoId'])\n",
    "            video_titles[video['videoId']] = video['title']['runs'][0]['text']\n",
    "    except:\n",
    "        with youtube_dl.YoutubeDL(youtube_dl_options) as ydl:\n",
    "            videos = ydl.extract_info(f'https://www.youtube.com/user/{channel_id}/videos')\n",
    "        for item in videos['entries']:\n",
    "            video_IDs.append(item['id'])\n",
    "            video_titles[item['id']] = item['title']\n",
    "            \n",
    "    if len(video_IDs) == 0:\n",
    "        with youtube_dl.YoutubeDL(youtube_dl_options) as ydl:\n",
    "            videos = ydl.extract_info(f'https://www.youtube.com/channel/{channel_id}')\n",
    "        for item in videos['entries']:\n",
    "            video_IDs.append(item['id'])\n",
    "            video_titles[item['id']] = item['title']\n",
    "        \n",
    "    return video_IDs, video_titles\n",
    "        \n",
    "def get_youtube_channel_id(channel_name):\n",
    "    try:\n",
    "        youtube = build('youtube', 'v3', developerKey=google_api_key)\n",
    "        channels_response = youtube.channels().list(\n",
    "                forUsername=channel_name,\n",
    "                part=\"id, snippet, statistics, contentDetails, topicDetails\"\n",
    "        ).execute()\n",
    "        response = channels_response['items'][0]['id']\n",
    "        return response\n",
    "    except:\n",
    "        return channel_name\n",
    "\n",
    "def save_audio_from_videoIDs(save_path, video_IDs):\n",
    "    for videoID in tqdm(video_IDs):\n",
    "        check_file = f\"{save_path}/{videoID}.mp3\"\n",
    "        if exists(check_file):\n",
    "            continue\n",
    "\n",
    "        # url of video to be downloaded\n",
    "        url = f\"https://youtu.be/{videoID}\"\n",
    "\n",
    "        # try to create a YouTube vid object\n",
    "        try:\n",
    "            yt = YouTube(url)\n",
    "        except RegexMatchError:\n",
    "            print(f\"RegexMatchError for '{url}'\")\n",
    "            continue\n",
    "\n",
    "        itag = None\n",
    "        # we only want audio files\n",
    "        files = yt.streams.filter(only_audio=True)\n",
    "        for file in files:\n",
    "            # and of those audio files we grab the first audio for mp4 (eg mp3)\n",
    "            if file.mime_type == 'audio/mp4':\n",
    "                itag = file.itag\n",
    "                break\n",
    "        if itag is None:\n",
    "            # just incase no MP3 audio is found (shouldn't happen)\n",
    "            print(\"NO MP3 AUDIO FOUND\")\n",
    "            continue\n",
    "\n",
    "        # get the correct mp3 'stream'\n",
    "        stream = yt.streams.get_by_itag(itag)\n",
    "        # downloading the audio\n",
    "        try:\n",
    "            # only download mp3 if it does not exist\n",
    "            stream.download(output_path=save_path, filename=f\"{videoID}.mp3\")\n",
    "        except:\n",
    "            print(f\"error downloading audio for video ID {videoID}\")\n",
    "            \n",
    "def get_text_from_data(start, end, data):\n",
    "    text = \"\"\n",
    "    for i in range(start,end):\n",
    "        text += data[i]['text']+' '\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cf30cf",
   "metadata": {},
   "source": [
    "## Initialize Whisper Model for transcription and Pinecone index\n",
    "Use GPU if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "886a5cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'dimension': 768,\n",
       " 'index_fullness': 0.4,\n",
       " 'namespaces': {'': {'vector_count': 805171}},\n",
       " 'total_vector_count': 805171}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "model = whisper.load_model(\"small\").to(device)\n",
    "\n",
    "model_id = \"multi-qa-mpnet-base-dot-v1\"\n",
    "model_embed = SentenceTransformer(model_id)\n",
    "dim = model_embed.get_sentence_embedding_dimension()\n",
    "\n",
    "pinecone.init(\n",
    "    api_key=pinecone_api_key,  # app.pinecone.io\n",
    "    environment=\"us-west1-gcp\"\n",
    ")\n",
    "if index_id not in pinecone.list_indexes():\n",
    "    pinecone.create_index(\n",
    "        index_id,\n",
    "        dim,\n",
    "        metric=\"dotproduct\"\n",
    "    )\n",
    "\n",
    "index = pinecone.Index(index_id)\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2ef3c3",
   "metadata": {},
   "source": [
    "## Create embeddings from youtube channel\n",
    "This takes a while to run as is it downloads and transcribes every video in the youtube channel<br>\n",
    "If videos do not download, try alternative methods as youtube channels are not setup consistently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1569fcba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paulharveyarchives\n",
      "[youtube:tab] UCiUcRrTAi6BBy3HqrA5543Q: Downloading webpage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Unable to download webpage: HTTP Error 404: Not Found (caused by <HTTPError 404: 'Not Found'>); please report this issue on https://yt-dl.org/bug . Make sure you are using the latest version; see  https://yt-dl.org/update  on how to update. Be sure to call youtube-dl with the --verbose flag and include its complete output.\n"
     ]
    }
   ],
   "source": [
    "for channel_name in channel_names:\n",
    "    try:\n",
    "        print(channel_name)\n",
    "        channel_id = get_youtube_channel_id(channel_name)\n",
    "        video_IDs, video_titles = get_all_video_in_channel(channel_id)\n",
    "        print(video_IDs)\n",
    "        save_audio_from_videoIDs(audio_dir, video_IDs)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    # get list of MP3 audio files\n",
    "    paths = [str(x) for x in Path(audio_dir).glob('*.mp3')]\n",
    "    \n",
    "    transcriptions = []\n",
    "    for i, path in enumerate(tqdm(paths)):\n",
    "        _id = path.split('/')[-1][:-4]\n",
    "        # transcribe to get speech-to-text data\n",
    "        print(path)\n",
    "        try:\n",
    "            result = model.transcribe(path)\n",
    "        except:\n",
    "            print('error, removing file ',path)\n",
    "            os.remove(path)\n",
    "            continue\n",
    "        # add results to data list\n",
    "        transcriptions.extend(result['segments'])\n",
    "        \n",
    "        # set window (length of text chunk) and stride\n",
    "        window = 1\n",
    "        stride = 1  # smaller stride creates overlap\n",
    "        \n",
    "        data = []\n",
    "        results = []\n",
    "    \n",
    "        with open(\"transcription.jsonl\", \"w\", encoding=\"utf-8\") as fp:\n",
    "            _id = path.split('/')[-1][:-4]\n",
    "            # transcribe to get speech-to-text data\n",
    "            result = model.transcribe(path)\n",
    "            segments = result['segments']\n",
    "            for j in range(0, len(segments), stride):\n",
    "                j_end = min(j+window, len(segments)-1)\n",
    "                text = ''.join([x[\"text\"] for x in segments[j:j_end]])\n",
    "                start = segments[j]['start']\n",
    "                end = segments[j_end]['end']\n",
    "                row_id = f\"{_id}-t{segments[j]['start']}\"\n",
    "                meta = {\n",
    "                    **{\n",
    "                        \"id\": row_id,\n",
    "                        \"text\": text.strip(),\n",
    "                        \"start\": start,\n",
    "                        \"end\": end,\n",
    "                        \"url\": f\"https://youtu.be/{_id}\",\n",
    "                        \"name\":_id,\n",
    "                        \"title\":video_titles[_id]\n",
    "                    }\n",
    "                }\n",
    "                data.append(meta)\n",
    "                json.dump(meta, fp)\n",
    "                fp.write('\\n')\n",
    "                    \n",
    "        new_data = []\n",
    "        \n",
    "        window = 6  # number of sentences to combine\n",
    "        stride = 3  # number of sentences to 'stride' over, used to create overlap\n",
    "        \n",
    "        for i in tqdm(range(0, len(data), stride)):\n",
    "            i_end = min(len(data)-1, i+window)\n",
    "            if data[i]['name'] != data[i_end]['name']:\n",
    "                # in this case we skip this entry as we have start/end of two videos\n",
    "                continue\n",
    "            text = get_text_from_data(i, i_end, data)\n",
    "            new_data.append({\n",
    "                'start': data[i]['start'],\n",
    "                'end': data[i_end]['end'],\n",
    "                'text': text,\n",
    "                'id': data[i]['id'],\n",
    "                'url': data[i]['url']+'?t='+str(int(data[i]['start'])),\n",
    "                \"name\":data[i]['name'],\n",
    "                \"title\":data[i]['title'],\n",
    "            })\n",
    "            \n",
    "        # loop through in batches of 64\n",
    "        index = pinecone.Index(index_id)\n",
    "        for j in tqdm(range(0, len(new_data), batch_size)):\n",
    "            # find end position of batch (for when we hit end of data)\n",
    "            j_end = min(len(new_data)-1, j+batch_size)\n",
    "            # extract the metadata like text, start/end positions, etc\n",
    "            batch_meta = [{\n",
    "                \"text\": new_data[x][\"text\"],\n",
    "                \"start\": new_data[x][\"start\"],\n",
    "                \"end\": new_data[x][\"end\"],\n",
    "                \"url\": new_data[x][\"url\"],\n",
    "                \"name\": new_data[x][\"name\"],\n",
    "                \"title\": new_data[x][\"title\"]\n",
    "            } for x in range(j, j_end)]\n",
    "            # extract only text to be encoded by embedding model\n",
    "            batch_text = [row['text'] for row in new_data[j:j_end]]\n",
    "            # create the embedding vectors\n",
    "            batch_embeds = model_embed.encode(batch_text).tolist()\n",
    "            # extract IDs to be attached to each embedding and metadata\n",
    "            batch_ids = [row['id'] for row in new_data[j:j_end]]\n",
    "            # 'upsert' (eg insert) IDs, embeddings, and metadata to index\n",
    "            try:\n",
    "                to_upsert = list(zip(batch_ids, batch_embeds, batch_meta))\n",
    "                index.upsert(to_upsert)\n",
    "            except:\n",
    "                continue\n",
    "        print('removing file ',path)\n",
    "        os.remove(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bb211b",
   "metadata": {},
   "source": [
    "## Query pinecone index for answer to question with video link in URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "030b5a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'matches': [{'id': 'My-I-6P_VUs-t676.68',\n",
      "              'metadata': {'end': 717.04,\n",
      "                           'name': 'My-I-6P_VUs',\n",
      "                           'start': 676.68,\n",
      "                           'text': \"using clip, what they're doing is they're \"\n",
      "                                   'using clip, which is a, you know, a model '\n",
      "                                   'that open AI released that they open AI '\n",
      "                                   'did not release sort of the generator '\n",
      "                                   'architecture on top of it. So the '\n",
      "                                   'community has, has kind of taken that and '\n",
      "                                   'applied another generator called DQ GAN. '\n",
      "                                   \"And so it's not even just taking one model \"\n",
      "                                   \"and changing the data set you're working \"\n",
      "                                   \"on, it's taking two models and then \"\n",
      "                                   'recomposing them in a really interesting '\n",
      "                                   \"way. So yeah, so I don't think we know \"\n",
      "                                   'exactly what the form factor is, but you '\n",
      "                                   'know, when ',\n",
      "                           'title': 'Compositional ML and the Future of '\n",
      "                                    'Software Development with Dillon Erb - '\n",
      "                                    '#520',\n",
      "                           'url': 'https://youtu.be/My-I-6P_VUs?t=676'},\n",
      "              'score': 28.9160156,\n",
      "              'sparseValues': {},\n",
      "              'values': []},\n",
      "             {'id': 'eJ4IeChWVz0-t1517.68',\n",
      "              'metadata': {'end': 1548.96,\n",
      "                           'name': 'eJ4IeChWVz0',\n",
      "                           'start': 1517.68,\n",
      "                           'text': \"Yeah, why don't you take a few moments to \"\n",
      "                                   'more deeply introduce Clip and why you '\n",
      "                                   'think it was so exciting? Clip is this '\n",
      "                                   'work from the OpenAI team. And basically, '\n",
      "                                   \"there's a lot of technical content that I \"\n",
      "                                   'will not spend time describing here. But '\n",
      "                                   'big picture is that they wanted ',\n",
      "                           'title': 'Trends in Computer Vision with Georgia '\n",
      "                                    'Gkioxari - #549',\n",
      "                           'url': 'https://youtu.be/eJ4IeChWVz0?t=1517'},\n",
      "              'score': 28.1160984,\n",
      "              'sparseValues': {},\n",
      "              'values': []},\n",
      "             {'id': 'HNJPasJUGqs-t262.84',\n",
      "              'metadata': {'end': 295.76,\n",
      "                           'name': 'HNJPasJUGqs',\n",
      "                           'start': 262.84,\n",
      "                           'text': \"Adversarial attacks. We know that OpenAI's \"\n",
      "                                   'clip responds to photos and drawings of '\n",
      "                                   \"the same thing, so let's try some nasty \"\n",
      "                                   'attacks involving combining the two. When '\n",
      "                                   'we give it these images, it can classify '\n",
      "                                   'them with ease. This is an apple, this is '\n",
      "                                   'a laptop, a mug, and so on. Nothing too '\n",
      "                                   'crazy going on here. ',\n",
      "                           'title': 'Do Neural Networks Think Like Our Brain? '\n",
      "                                    'OpenAI Answers! 🧠',\n",
      "                           'url': 'https://youtu.be/HNJPasJUGqs?t=262'},\n",
      "              'score': 26.884819,\n",
      "              'sparseValues': {},\n",
      "              'values': []},\n",
      "             {'id': 'zmlHI2kAqmk-t115.84',\n",
      "              'metadata': {'end': 157.96,\n",
      "                           'name': 'zmlHI2kAqmk',\n",
      "                           'start': 115.84,\n",
      "                           'text': \"Now we're seeing, I think, even a step \"\n",
      "                                   'beyond that which is, in the case of this '\n",
      "                                   'creative artistic community using Clip, '\n",
      "                                   \"what they're doing is they're using Clip, \"\n",
      "                                   'which is a model that OpenAI released that '\n",
      "                                   'they open AI did not release the generator '\n",
      "                                   'architecture on top of it. The community '\n",
      "                                   'has taken that and applied another '\n",
      "                                   \"generator called VQGAN. It's not even just \"\n",
      "                                   'taking one model and changing the data set '\n",
      "                                   \"you're working on. \",\n",
      "                           'title': 'Evolution of Machine Learning as a SWE '\n",
      "                                    'Discipline - Clips - #520',\n",
      "                           'url': 'https://youtu.be/zmlHI2kAqmk?t=115'},\n",
      "              'score': 26.7587776,\n",
      "              'sparseValues': {},\n",
      "              'values': []},\n",
      "             {'id': 'eJ4IeChWVz0-t1506.84',\n",
      "              'metadata': {'end': 1536.44,\n",
      "                           'name': 'eJ4IeChWVz0',\n",
      "                           'start': 1506.84,\n",
      "                           'text': \"And that's what they showed. They showed \"\n",
      "                                   'that that creates a great representation '\n",
      "                                   \"if you're trying to jointly capture text \"\n",
      "                                   \"with images. Yeah, why don't you take a \"\n",
      "                                   'few moments to more deeply introduce Clip '\n",
      "                                   'and why you think it was so exciting? Clip '\n",
      "                                   'is this work from the OpenAI team. ',\n",
      "                           'title': 'Trends in Computer Vision with Georgia '\n",
      "                                    'Gkioxari - #549',\n",
      "                           'url': 'https://youtu.be/eJ4IeChWVz0?t=1506'},\n",
      "              'score': 26.3277893,\n",
      "              'sparseValues': {},\n",
      "              'values': []}],\n",
      " 'namespace': ''}\n"
     ]
    }
   ],
   "source": [
    "# Define the query or question to ask\n",
    "query = \"what is OpenAI's CLIP?\"\n",
    "# Create and embedding representing the question\n",
    "xq = model_embed.encode(query).tolist()\n",
    "# Search the index for the top (k) answers \n",
    "results = index.query(xq, top_k=5, include_metadata=True)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba186096",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
